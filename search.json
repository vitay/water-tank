[
  {
    "objectID": "reference/TimeSeriesInput.html",
    "href": "reference/TimeSeriesInput.html",
    "title": "TimeSeriesInput",
    "section": "",
    "text": "TimeSeriesInput(self, size, loop=True)\nDynamic placeholder for series of input vectors.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsize\nint\nsize of the input vector.\nrequired\n\n\nloop\nbool\ndefines whether the buffer loops when arriving at the end.\nTrue\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\noutput\n\n\n\nreset\nResets the buffer.\n\n\nset\nSets the buffer to value.\n\n\nstep\nReads the next value.\n\n\n\n\n\nTimeSeriesInput.output(self)\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.ndarray\na vector of activities.\n\n\n\n\n\n\n\nTimeSeriesInput.reset(self)\nResets the buffer.\n\n\n\nTimeSeriesInput.set(self, value)\nSets the buffer to value.\n\n\n\nTimeSeriesInput.step(self)\nReads the next value."
  },
  {
    "objectID": "reference/TimeSeriesInput.html#parameters",
    "href": "reference/TimeSeriesInput.html#parameters",
    "title": "TimeSeriesInput",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nsize\nint\nsize of the input vector.\nrequired\n\n\nloop\nbool\ndefines whether the buffer loops when arriving at the end.\nTrue"
  },
  {
    "objectID": "reference/TimeSeriesInput.html#methods",
    "href": "reference/TimeSeriesInput.html#methods",
    "title": "TimeSeriesInput",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\noutput\n\n\n\nreset\nResets the buffer.\n\n\nset\nSets the buffer to value.\n\n\nstep\nReads the next value.\n\n\n\n\n\nTimeSeriesInput.output(self)\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.ndarray\na vector of activities.\n\n\n\n\n\n\n\nTimeSeriesInput.reset(self)\nResets the buffer.\n\n\n\nTimeSeriesInput.set(self, value)\nSets the buffer to value.\n\n\n\nTimeSeriesInput.step(self)\nReads the next value."
  },
  {
    "objectID": "reference/Normal.html",
    "href": "reference/Normal.html",
    "title": "Normal",
    "section": "",
    "text": "Normal(self, mean, std)\nNormal distribution, returning values with a mean of mean and a standard deviation of std.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmean\nfloat\nmean.\nrequired\n\n\nstd\nfloat\nstandard deviation.\nrequired\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nsample\nSamples from the distribution and returns an array of the desired shape.\n\n\n\n\n\nNormal.sample(self, shape)\nSamples from the distribution and returns an array of the desired shape."
  },
  {
    "objectID": "reference/Normal.html#parameters",
    "href": "reference/Normal.html#parameters",
    "title": "Normal",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nmean\nfloat\nmean.\nrequired\n\n\nstd\nfloat\nstandard deviation.\nrequired"
  },
  {
    "objectID": "reference/Normal.html#methods",
    "href": "reference/Normal.html#methods",
    "title": "Normal",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nsample\nSamples from the distribution and returns an array of the desired shape.\n\n\n\n\n\nNormal.sample(self, shape)\nSamples from the distribution and returns an array of the desired shape."
  },
  {
    "objectID": "reference/Uniform.html",
    "href": "reference/Uniform.html",
    "title": "Uniform",
    "section": "",
    "text": "Uniform(self, min, max)\nUniform distribution, returning values between min and max.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmin\nfloat\nlower bound.\nrequired\n\n\nmax\nfloat\nupper bound.\nrequired\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nsample\nSamples from the distribution and returns an array of the desired shape.\n\n\n\n\n\nUniform.sample(self, shape)\nSamples from the distribution and returns an array of the desired shape."
  },
  {
    "objectID": "reference/Uniform.html#parameters",
    "href": "reference/Uniform.html#parameters",
    "title": "Uniform",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nmin\nfloat\nlower bound.\nrequired\n\n\nmax\nfloat\nupper bound.\nrequired"
  },
  {
    "objectID": "reference/Uniform.html#methods",
    "href": "reference/Uniform.html#methods",
    "title": "Uniform",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nsample\nSamples from the distribution and returns an array of the desired shape.\n\n\n\n\n\nUniform.sample(self, shape)\nSamples from the distribution and returns an array of the desired shape."
  },
  {
    "objectID": "reference/StaticInput.html",
    "href": "reference/StaticInput.html",
    "title": "StaticInput",
    "section": "",
    "text": "StaticInput(self, size)\nStatic placeholder for input vectors.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsize\nint\nsize of the vector.\nrequired\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\noutput\n\n\n\nset\nSets the value of the vector. The dimensions must match with self.size.\n\n\nstep\nDoes nothing.\n\n\n\n\n\nStaticInput.output(self)\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.ndarray\na vector of activities.\n\n\n\n\n\n\n\nStaticInput.set(self, value)\nSets the value of the vector. The dimensions must match with self.size.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvalue\nnumpy.ndarray\nnew vector value.\nrequired\n\n\n\n\n\n\n\nStaticInput.step(self)\nDoes nothing."
  },
  {
    "objectID": "reference/StaticInput.html#parameters",
    "href": "reference/StaticInput.html#parameters",
    "title": "StaticInput",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nsize\nint\nsize of the vector.\nrequired"
  },
  {
    "objectID": "reference/StaticInput.html#methods",
    "href": "reference/StaticInput.html#methods",
    "title": "StaticInput",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\noutput\n\n\n\nset\nSets the value of the vector. The dimensions must match with self.size.\n\n\nstep\nDoes nothing.\n\n\n\n\n\nStaticInput.output(self)\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.ndarray\na vector of activities.\n\n\n\n\n\n\n\nStaticInput.set(self, value)\nSets the value of the vector. The dimensions must match with self.size.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvalue\nnumpy.ndarray\nnew vector value.\nrequired\n\n\n\n\n\n\n\nStaticInput.step(self)\nDoes nothing."
  },
  {
    "objectID": "reference/DeltaLearningRule.html",
    "href": "reference/DeltaLearningRule.html",
    "title": "DeltaLearningRule",
    "section": "",
    "text": "DeltaLearningRule\nDeltaLearningRule(self, projection, learning_rate)"
  },
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "API reference",
    "section": "",
    "text": "Layers available for inputs, reservoirs, readouts, etc.\n\n\n\nRecurrentLayer\nReservoir of recurrently connected neurons.\n\n\nLinearReadout\nLinear readout layer. Performs a weighted sum of its inputs, without dynamics.\n\n\nStaticInput\nStatic placeholder for input vectors.\n\n\nTimeSeriesInput\nDynamic placeholder for series of input vectors.\n\n\n\n\n\n\nConnecting layers with each other.\n\n\n\nconnect\nConnects two layers with a (sparse) weight matrix and optionally a bias vector.\n\n\nDenseProjection\nDense weight matrix. Created and returned by connect().\n\n\nSparseProjection\nSparse weight matrix. Created and returned by connect().\n\n\n\n\n\n\nLearning rules for online training of a projection.\n\n\n\nDeltaLearningRule\n\n\n\nRLS\nRecursive least-squares (RLS) learning rule for FORCE learning.\n\n\n\n\n\n\nSimple wrappers around numpy’s random distributions.\n\n\n\nConst\nConstant “random” distribution, returning the same value.\n\n\nUniform\nUniform distribution, returning values between min and max.\n\n\nNormal\nNormal distribution, returning values with a mean of mean and a standard deviation of std.\n\n\nBernouilli\nBernouilli (binomial) distribution, returning the first of the two values with probability p."
  },
  {
    "objectID": "reference/index.html#layers",
    "href": "reference/index.html#layers",
    "title": "API reference",
    "section": "",
    "text": "Layers available for inputs, reservoirs, readouts, etc.\n\n\n\nRecurrentLayer\nReservoir of recurrently connected neurons.\n\n\nLinearReadout\nLinear readout layer. Performs a weighted sum of its inputs, without dynamics.\n\n\nStaticInput\nStatic placeholder for input vectors.\n\n\nTimeSeriesInput\nDynamic placeholder for series of input vectors."
  },
  {
    "objectID": "reference/index.html#projections",
    "href": "reference/index.html#projections",
    "title": "API reference",
    "section": "",
    "text": "Connecting layers with each other.\n\n\n\nconnect\nConnects two layers with a (sparse) weight matrix and optionally a bias vector.\n\n\nDenseProjection\nDense weight matrix. Created and returned by connect().\n\n\nSparseProjection\nSparse weight matrix. Created and returned by connect()."
  },
  {
    "objectID": "reference/index.html#learning-rules",
    "href": "reference/index.html#learning-rules",
    "title": "API reference",
    "section": "",
    "text": "Learning rules for online training of a projection.\n\n\n\nDeltaLearningRule\n\n\n\nRLS\nRecursive least-squares (RLS) learning rule for FORCE learning."
  },
  {
    "objectID": "reference/index.html#random-distributions",
    "href": "reference/index.html#random-distributions",
    "title": "API reference",
    "section": "",
    "text": "Simple wrappers around numpy’s random distributions.\n\n\n\nConst\nConstant “random” distribution, returning the same value.\n\n\nUniform\nUniform distribution, returning values between min and max.\n\n\nNormal\nNormal distribution, returning values with a mean of mean and a standard deviation of std.\n\n\nBernouilli\nBernouilli (binomial) distribution, returning the first of the two values with probability p."
  },
  {
    "objectID": "reference/RecurrentLayer.html",
    "href": "reference/RecurrentLayer.html",
    "title": "RecurrentLayer",
    "section": "",
    "text": "RecurrentLayer(self, size, tau=10.0, transfer_function='tanh')\nReservoir of recurrently connected neurons.\n\\tau \\, \\frac{d \\mathbf{x}(t)}{dt} + \\mathbf{x}(t) = W^\\text{in} \\times I(t) + W^\\text{rec} \\times \\mathbf{r}(t) + W^\\text{fb} \\times \\mathbf{z}(t)\n\\mathbf{r}(t) = f(\\mathbf{x}(t))\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsize\nint\nnumber of neurons.\nrequired\n\n\ntau\nfloat\ntime constant.\n10.0\n\n\ntransfer_function\nstr\ntransfer function.\n'tanh'\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\noutput\n\n\n\nstep\nPerforms one update of the internal variables.\n\n\n\n\n\nRecurrentLayer.output(self)\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\na vector of activities.\n\n\n\n\n\n\n\nRecurrentLayer.step(self)\nPerforms one update of the internal variables."
  },
  {
    "objectID": "reference/RecurrentLayer.html#parameters",
    "href": "reference/RecurrentLayer.html#parameters",
    "title": "RecurrentLayer",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nsize\nint\nnumber of neurons.\nrequired\n\n\ntau\nfloat\ntime constant.\n10.0\n\n\ntransfer_function\nstr\ntransfer function.\n'tanh'"
  },
  {
    "objectID": "reference/RecurrentLayer.html#methods",
    "href": "reference/RecurrentLayer.html#methods",
    "title": "RecurrentLayer",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\noutput\n\n\n\nstep\nPerforms one update of the internal variables.\n\n\n\n\n\nRecurrentLayer.output(self)\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\na vector of activities.\n\n\n\n\n\n\n\nRecurrentLayer.step(self)\nPerforms one update of the internal variables."
  },
  {
    "objectID": "reference/Bernouilli.html",
    "href": "reference/Bernouilli.html",
    "title": "Bernouilli",
    "section": "",
    "text": "Bernouilli(self, values, p=0.5)\nBernouilli (binomial) distribution, returning the first of the two values with probability p.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvalues\nlist\nlist of values.\nrequired\n\n\np\nfloat\nprobability of returning the first value.\n0.5\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nsample\nSamples from the distribution and returns an array of the desired shape.\n\n\n\n\n\nBernouilli.sample(self, shape)\nSamples from the distribution and returns an array of the desired shape."
  },
  {
    "objectID": "reference/Bernouilli.html#parameters",
    "href": "reference/Bernouilli.html#parameters",
    "title": "Bernouilli",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nvalues\nlist\nlist of values.\nrequired\n\n\np\nfloat\nprobability of returning the first value.\n0.5"
  },
  {
    "objectID": "reference/Bernouilli.html#methods",
    "href": "reference/Bernouilli.html#methods",
    "title": "Bernouilli",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nsample\nSamples from the distribution and returns an array of the desired shape.\n\n\n\n\n\nBernouilli.sample(self, shape)\nSamples from the distribution and returns an array of the desired shape."
  },
  {
    "objectID": "reference/connect.html",
    "href": "reference/connect.html",
    "title": "connect",
    "section": "",
    "text": "connect(pre, post, weights, bias=None, sparseness=1.0)\nConnects two layers with a (sparse) weight matrix and optionally a bias vector.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npre\nLayer\ninput layer.\nrequired\n\n\npost\nLayer\noutput layer.\nrequired\n\n\nweights\ntyping.Union[float, water_tank.RandomDistributions.RandomDistribution]\nfloat or RandomDistribution to create the weight matrix.\nrequired\n\n\nbias\ntyping.Union[float, water_tank.RandomDistributions.RandomDistribution]\nbias per post neuron. If None or False, no bias is used. Otherwise, can be a float or RandomDistribution.\nNone\n\n\nsparseness\nfloat\ndensity of the weight matrix.\n1.0\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nProjection\na DenseProjection or SparseProjection instance."
  },
  {
    "objectID": "reference/connect.html#parameters",
    "href": "reference/connect.html#parameters",
    "title": "connect",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\npre\nLayer\ninput layer.\nrequired\n\n\npost\nLayer\noutput layer.\nrequired\n\n\nweights\ntyping.Union[float, water_tank.RandomDistributions.RandomDistribution]\nfloat or RandomDistribution to create the weight matrix.\nrequired\n\n\nbias\ntyping.Union[float, water_tank.RandomDistributions.RandomDistribution]\nbias per post neuron. If None or False, no bias is used. Otherwise, can be a float or RandomDistribution.\nNone\n\n\nsparseness\nfloat\ndensity of the weight matrix.\n1.0"
  },
  {
    "objectID": "reference/connect.html#returns",
    "href": "reference/connect.html#returns",
    "title": "connect",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\nProjection\na DenseProjection or SparseProjection instance."
  },
  {
    "objectID": "reference/RLS.html",
    "href": "reference/RLS.html",
    "title": "RLS",
    "section": "",
    "text": "RLS\nRLS(self, projection, delta)\nRecursive least-squares (RLS) learning rule for FORCE learning."
  },
  {
    "objectID": "notebooks/MackeyGlass.html",
    "href": "notebooks/MackeyGlass.html",
    "title": "Mackey-Glass autoregression",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\nimport water_tank as wt\n\n\nN_in = 1 # number of inputs\nN_out = 1 # number of outputs\nN = 200 # number of neurons\ng = 1.25 # scaling factor\ntau = 3.3 # time constant\nsparseness = 0.1 # sparseness of the recurrent weights\n\n\nclass RC(object):\n\n    def __init__(self, N, N_in, N_out, g, tau, sparseness):\n\n        # Input population\n        self.inp = wt.StaticInput(size=N_in)\n\n        # Reservoir \n        self.rc = wt.Reservoir(size=N, tau=tau)\n\n        # Readout\n        self.readout = wt.LinearReadout(size=N_out)\n\n        # Input projection\n        self.inp_proj = wt.connect(\n            pre=self.inp, \n            post=self.rc, \n            weights=wt.Bernouilli([-1.0, 1.0], p=0.5), \n            bias=wt.Bernouilli([-1.0, 1.0], p=0.5), # very important\n            sparseness=0.1\n        )\n\n        # Recurrent projection\n        self.rec_proj = wt.connect(\n            pre=self.rc, \n            post=self.rc, \n            weights=wt.Normal(0.0, g/np.sqrt(sparseness*N)), \n            bias=None,\n            sparseness=sparseness)\n\n        # Readout projection\n        self.readout_proj = wt.connect(\n            pre = self.rc, \n            post = self.readout,\n            weights = wt.Uniform(-0.01, 0.01), # very small but not zero\n            bias=wt.Const(0.0), # learnable bias\n            sparseness=1.0 # readout should be dense\n        )\n\n        # Feedback projection\n        #self.feedback_proj = wt.connect(self.readout, self.rc, wt.Uniform(-1.0, 1.0))\n\n        # Learning rules\n        #self.learningrule = wt.DeltaLearningRule(projection=self.readout_proj, learning_rate=0.01)\n        self.learningrule = wt.RLS(projection=self.readout_proj, delta=1e-6)\n\n        # Recorder\n        self.recorder = wt.Recorder()\n\n    @wt.measure\n    def train(self, X, Y, warmup=0):\n\n        for t, (x, y) in enumerate(zip(X, Y)): \n\n            # Inputs/targets\n            self.inp.set(x)\n\n            # Steps \n            self.rc.step() \n            self.readout.step()\n\n            # Learning\n            if t &gt;= warmup: self.learningrule.step(target=y)\n\n            # Recording\n            self.recorder.record({\n                'rc': self.rc.output(), \n                'readout': self.readout.output(),\n            })\n    \n    @wt.measure\n    def autoregressive(self, duration):\n\n        for _ in range(duration): \n            # Autoregressive input\n            self.inp.set(self.readout.output())  \n\n            # Steps \n            self.rc.step() \n            self.readout.step()\n\n            # Recording\n            self.recorder.record({\n                'rc': self.rc.output(), \n                'readout': self.readout.output()\n            })\n\n\nfrom reservoirpy.datasets import mackey_glass\n\n# Mackey-Glass chaotic time series\nT = 2000\nmg = mackey_glass(T)\nmg =  2.0 * (mg - mg.min()) / (mg.max() - mg.min()) - 1.0\nX = mg[:-1, 0]\nY = mg[1:, 0]\n\n\nnet = RC(N, N_in, N_out, g, tau, sparseness)\n\n# Training / test\nd_train = 500\nd_test = 1000\n\n# Supervised training\nnet.train(X[:d_train], Y[:d_train], warmup=0)\ndata_train = net.recorder.get()\n\n# Autoregressive test\nnet.autoregressive(duration=d_test)\ndata_test = net.recorder.get()\n\nExecution time: 716 ms\nExecution time: 27 ms\n\n\n\nplt.figure()\nplt.title(\"Autoregression\")\nplt.subplot(211)\nplt.plot(Y[:d_train], label='ground truth (training)')\nplt.plot(data_train['readout'][:, 0], label='prediction (training)')\nplt.plot(np.linspace(d_train, d_train+d_test, d_test), Y[d_train:d_train+d_test], label='ground truth (test)')\nplt.plot(np.linspace(d_train, d_train+d_test, d_test), data_test['readout'][:, 0], label='prediction (test)')\nplt.legend()\nplt.subplot(212)\nplt.plot(Y[:d_train+d_test] - np.concatenate((data_train['readout'][:, 0], data_test['readout'][:, 0])), label='error')\nplt.legend()\n\nplt.show()\n\n/var/folders/6w/6msx49ws7k13cc0bbys0tt4m0000gn/T/ipykernel_33855/2895089909.py:3: MatplotlibDeprecationWarning: Auto-removal of overlapping axes is deprecated since 3.6 and will be removed two minor releases later; explicitly call ax.remove() as needed.\n  plt.subplot(211)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Water Tank",
    "section": "",
    "text": "Water tanks are plastic reservoirs.\n\n\nDependencies:\n\npython&gt;= 3.9\nnumpy &gt;= 1.21\nscipy&gt;= 1.11\n\nIn a virtual environment:\npip install git+https://github.com/vitay/water-tank.git@master\n\n\n\nwater-tank is distributed under the terms of the MIT license."
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "Water Tank",
    "section": "",
    "text": "Dependencies:\n\npython&gt;= 3.9\nnumpy &gt;= 1.21\nscipy&gt;= 1.11\n\nIn a virtual environment:\npip install git+https://github.com/vitay/water-tank.git@master"
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Water Tank",
    "section": "",
    "text": "water-tank is distributed under the terms of the MIT license."
  },
  {
    "objectID": "License.html",
    "href": "License.html",
    "title": "License",
    "section": "",
    "text": "License\n\nMIT License\nCopyright (c) 2023-present Julien Vitay julien.vitay@informatik.tu-chemnitz.de\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "reference/RandomDistributions.Uniform.html",
    "href": "reference/RandomDistributions.Uniform.html",
    "title": "RandomDistributions.Uniform",
    "section": "",
    "text": "RandomDistributions.Uniform(self, min, max)\nUniform distribution, returning values between min and max.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmin\nfloat\nlower bound.\nrequired\n\n\nmax\nfloat\nupper bound.\nrequired\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nsample\nSamples from the distribution and returns an array of the desired shape.\n\n\n\n\n\nRandomDistributions.Uniform.sample(self, shape)\nSamples from the distribution and returns an array of the desired shape."
  },
  {
    "objectID": "reference/RandomDistributions.Uniform.html#parameters",
    "href": "reference/RandomDistributions.Uniform.html#parameters",
    "title": "RandomDistributions.Uniform",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nmin\nfloat\nlower bound.\nrequired\n\n\nmax\nfloat\nupper bound.\nrequired"
  },
  {
    "objectID": "reference/RandomDistributions.Uniform.html#methods",
    "href": "reference/RandomDistributions.Uniform.html#methods",
    "title": "RandomDistributions.Uniform",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nsample\nSamples from the distribution and returns an array of the desired shape.\n\n\n\n\n\nRandomDistributions.Uniform.sample(self, shape)\nSamples from the distribution and returns an array of the desired shape."
  },
  {
    "objectID": "reference/LinearReadout.html",
    "href": "reference/LinearReadout.html",
    "title": "LinearReadout",
    "section": "",
    "text": "LinearReadout(self, size)\nLinear readout layer. Performs a weighted sum of its inputs, without dynamics.\n\\mathbf{z} = W^o \\times \\mathbf{r}\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsize\nint\nnumber of neurons.\nrequired\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\noutput\n\n\n\nstep\nPerforms one update of the internal variables.\n\n\n\n\n\nLinearReadout.output(self)\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.ndarray\na vector of activities.\n\n\n\n\n\n\n\nLinearReadout.step(self, force=None)\nPerforms one update of the internal variables.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nforce\nnumpy.ndarray\nif not None, force the output to the provided vector.\nNone"
  },
  {
    "objectID": "reference/LinearReadout.html#parameters",
    "href": "reference/LinearReadout.html#parameters",
    "title": "LinearReadout",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nsize\nint\nnumber of neurons.\nrequired"
  },
  {
    "objectID": "reference/LinearReadout.html#methods",
    "href": "reference/LinearReadout.html#methods",
    "title": "LinearReadout",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\noutput\n\n\n\nstep\nPerforms one update of the internal variables.\n\n\n\n\n\nLinearReadout.output(self)\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.ndarray\na vector of activities.\n\n\n\n\n\n\n\nLinearReadout.step(self, force=None)\nPerforms one update of the internal variables.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nforce\nnumpy.ndarray\nif not None, force the output to the provided vector.\nNone"
  },
  {
    "objectID": "reference/RandomDistributions.Const.html",
    "href": "reference/RandomDistributions.Const.html",
    "title": "RandomDistributions.Const",
    "section": "",
    "text": "RandomDistributions.Const(self, value)\nConstant “random” distribution, returning the same value.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvalue\nfloat\nconstant value.\nrequired\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nsample\nSamples from the distribution and returns an array of the desired shape.\n\n\n\n\n\nRandomDistributions.Const.sample(self, shape)\nSamples from the distribution and returns an array of the desired shape."
  },
  {
    "objectID": "reference/RandomDistributions.Const.html#parameters",
    "href": "reference/RandomDistributions.Const.html#parameters",
    "title": "RandomDistributions.Const",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nvalue\nfloat\nconstant value.\nrequired"
  },
  {
    "objectID": "reference/RandomDistributions.Const.html#methods",
    "href": "reference/RandomDistributions.Const.html#methods",
    "title": "RandomDistributions.Const",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nsample\nSamples from the distribution and returns an array of the desired shape.\n\n\n\n\n\nRandomDistributions.Const.sample(self, shape)\nSamples from the distribution and returns an array of the desired shape."
  },
  {
    "objectID": "reference/RandomDistributions.Bernouilli.html",
    "href": "reference/RandomDistributions.Bernouilli.html",
    "title": "RandomDistributions.Bernouilli",
    "section": "",
    "text": "RandomDistributions.Bernouilli(self, values, p=0.5)\nBernouilli (binomial) distribution, returning the first of the two values with probability p.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvalues\nlist\nlist of values.\nrequired\n\n\np\nfloat\nprobability of returning the first value.\n0.5\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nsample\nSamples from the distribution and returns an array of the desired shape.\n\n\n\n\n\nRandomDistributions.Bernouilli.sample(self, shape)\nSamples from the distribution and returns an array of the desired shape."
  },
  {
    "objectID": "reference/RandomDistributions.Bernouilli.html#parameters",
    "href": "reference/RandomDistributions.Bernouilli.html#parameters",
    "title": "RandomDistributions.Bernouilli",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nvalues\nlist\nlist of values.\nrequired\n\n\np\nfloat\nprobability of returning the first value.\n0.5"
  },
  {
    "objectID": "reference/RandomDistributions.Bernouilli.html#methods",
    "href": "reference/RandomDistributions.Bernouilli.html#methods",
    "title": "RandomDistributions.Bernouilli",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nsample\nSamples from the distribution and returns an array of the desired shape.\n\n\n\n\n\nRandomDistributions.Bernouilli.sample(self, shape)\nSamples from the distribution and returns an array of the desired shape."
  },
  {
    "objectID": "reference/RandomDistributions.Normal.html",
    "href": "reference/RandomDistributions.Normal.html",
    "title": "RandomDistributions.Normal",
    "section": "",
    "text": "RandomDistributions.Normal(self, mean, std)\nNormal distribution, returning values with a mean of mean and a standard deviation of std.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmean\nfloat\nmean.\nrequired\n\n\nstd\nfloat\nstandard deviation.\nrequired\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nsample\nSamples from the distribution and returns an array of the desired shape.\n\n\n\n\n\nRandomDistributions.Normal.sample(self, shape)\nSamples from the distribution and returns an array of the desired shape."
  },
  {
    "objectID": "reference/RandomDistributions.Normal.html#parameters",
    "href": "reference/RandomDistributions.Normal.html#parameters",
    "title": "RandomDistributions.Normal",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nmean\nfloat\nmean.\nrequired\n\n\nstd\nfloat\nstandard deviation.\nrequired"
  },
  {
    "objectID": "reference/RandomDistributions.Normal.html#methods",
    "href": "reference/RandomDistributions.Normal.html#methods",
    "title": "RandomDistributions.Normal",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nsample\nSamples from the distribution and returns an array of the desired shape.\n\n\n\n\n\nRandomDistributions.Normal.sample(self, shape)\nSamples from the distribution and returns an array of the desired shape."
  },
  {
    "objectID": "reference/Const.html",
    "href": "reference/Const.html",
    "title": "Const",
    "section": "",
    "text": "Const(self, value)\nConstant “random” distribution, returning the same value.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvalue\nfloat\nconstant value.\nrequired\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nsample\nSamples from the distribution and returns an array of the desired shape.\n\n\n\n\n\nConst.sample(self, shape)\nSamples from the distribution and returns an array of the desired shape."
  },
  {
    "objectID": "reference/Const.html#parameters",
    "href": "reference/Const.html#parameters",
    "title": "Const",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nvalue\nfloat\nconstant value.\nrequired"
  },
  {
    "objectID": "reference/Const.html#methods",
    "href": "reference/Const.html#methods",
    "title": "Const",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nsample\nSamples from the distribution and returns an array of the desired shape.\n\n\n\n\n\nConst.sample(self, shape)\nSamples from the distribution and returns an array of the desired shape."
  },
  {
    "objectID": "reference/DenseProjection.html",
    "href": "reference/DenseProjection.html",
    "title": "DenseProjection",
    "section": "",
    "text": "DenseProjection(self, pre, post, weights, bias=None)\nDense weight matrix. Created and returned by connect().\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npre\nLayer\ninput layer.\nrequired\n\n\npost\nLayer\noutput layer.\nrequired\n\n\nweights\ntyping.Union[float, water_tank.RandomDistributions.RandomDistribution]\nfloat or RandomDistribution to create the weight matrix.\nrequired\n\n\nbias\ntyping.Union[float, water_tank.RandomDistributions.RandomDistribution]\nbias per post neuron. If None or False, no bias is used. Otherwise, can be a float or RandomDistribution.\nNone\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ninput\n\n\n\nnb_connections\n\n\n\nstep\nPerforms a weighted sum of inputs plus bias.\n\n\n\n\n\nDenseProjection.input(self, idx)\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.ndarray\nthe vector of inputs received by the neuron of index idx.\n\n\n\n\n\n\n\nDenseProjection.nb_connections(self, idx)\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nint\nthe number of weights received by the neuron of index idx.\n\n\n\n\n\n\n\nDenseProjection.step(self)\nPerforms a weighted sum of inputs plus bias."
  },
  {
    "objectID": "reference/DenseProjection.html#parameters",
    "href": "reference/DenseProjection.html#parameters",
    "title": "DenseProjection",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\npre\nLayer\ninput layer.\nrequired\n\n\npost\nLayer\noutput layer.\nrequired\n\n\nweights\ntyping.Union[float, water_tank.RandomDistributions.RandomDistribution]\nfloat or RandomDistribution to create the weight matrix.\nrequired\n\n\nbias\ntyping.Union[float, water_tank.RandomDistributions.RandomDistribution]\nbias per post neuron. If None or False, no bias is used. Otherwise, can be a float or RandomDistribution.\nNone"
  },
  {
    "objectID": "reference/DenseProjection.html#methods",
    "href": "reference/DenseProjection.html#methods",
    "title": "DenseProjection",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ninput\n\n\n\nnb_connections\n\n\n\nstep\nPerforms a weighted sum of inputs plus bias.\n\n\n\n\n\nDenseProjection.input(self, idx)\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.ndarray\nthe vector of inputs received by the neuron of index idx.\n\n\n\n\n\n\n\nDenseProjection.nb_connections(self, idx)\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nint\nthe number of weights received by the neuron of index idx.\n\n\n\n\n\n\n\nDenseProjection.step(self)\nPerforms a weighted sum of inputs plus bias."
  },
  {
    "objectID": "reference/SparseProjection.html",
    "href": "reference/SparseProjection.html",
    "title": "SparseProjection",
    "section": "",
    "text": "SparseProjection(self, pre, post, weights, bias=None, sparseness=0.1)\nSparse weight matrix. Created and returned by connect().\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npre\nLayer\ninput layer.\nrequired\n\n\npost\nLayer\noutput layer.\nrequired\n\n\nweights\ntyping.Union[float, water_tank.RandomDistributions.RandomDistribution]\nfloat or RandomDistribution to create the weight matrix.\nrequired\n\n\nbias\ntyping.Union[float, water_tank.RandomDistributions.RandomDistribution]\nbias per post neuron. If None or False, no bias is used. Otherwise, can be a float or RandomDistribution.\nNone\n\n\nsparseness\nfloat\ndensity of the weight matrix.\n0.1\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ninput\n\n\n\nnb_connections\n\n\n\nstep\nPerforms a weighted sum of inputs plus bias.\n\n\n\n\n\nSparseProjection.input(self, idx)\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.ndarray\nthe vector of inputs received by the neuron of index idx.\n\n\n\n\n\n\n\nSparseProjection.nb_connections(self, idx)\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nint\nthe number of weights received by the neuron of index idx.\n\n\n\n\n\n\n\nSparseProjection.step(self)\nPerforms a weighted sum of inputs plus bias."
  },
  {
    "objectID": "reference/SparseProjection.html#parameters",
    "href": "reference/SparseProjection.html#parameters",
    "title": "SparseProjection",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\npre\nLayer\ninput layer.\nrequired\n\n\npost\nLayer\noutput layer.\nrequired\n\n\nweights\ntyping.Union[float, water_tank.RandomDistributions.RandomDistribution]\nfloat or RandomDistribution to create the weight matrix.\nrequired\n\n\nbias\ntyping.Union[float, water_tank.RandomDistributions.RandomDistribution]\nbias per post neuron. If None or False, no bias is used. Otherwise, can be a float or RandomDistribution.\nNone\n\n\nsparseness\nfloat\ndensity of the weight matrix.\n0.1"
  },
  {
    "objectID": "reference/SparseProjection.html#methods",
    "href": "reference/SparseProjection.html#methods",
    "title": "SparseProjection",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ninput\n\n\n\nnb_connections\n\n\n\nstep\nPerforms a weighted sum of inputs plus bias.\n\n\n\n\n\nSparseProjection.input(self, idx)\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.ndarray\nthe vector of inputs received by the neuron of index idx.\n\n\n\n\n\n\n\nSparseProjection.nb_connections(self, idx)\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nint\nthe number of weights received by the neuron of index idx.\n\n\n\n\n\n\n\nSparseProjection.step(self)\nPerforms a weighted sum of inputs plus bias."
  },
  {
    "objectID": "reference/index.qmd.html",
    "href": "reference/index.qmd.html",
    "title": "Layers",
    "section": "",
    "text": "Layers available for inputs, reservoirs, readouts, etc.\n\n\nRecurrentLayer(self, size, tau=10.0, transfer_function='tanh')\nReservoir of recurrently connected neurons.\n\\tau \\, \\frac{d \\mathbf{x}(t)}{dt} + \\mathbf{x}(t) = W^\\text{in} \\times I(t) + W^\\text{rec} \\times \\mathbf{r}(t) + W^\\text{fb} \\times \\mathbf{z}(t)\n\\mathbf{r}(t) = f(\\mathbf{x}(t))\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsize\nint\nnumber of neurons.\nrequired\n\n\ntau\nfloat\ntime constant.\n10.0\n\n\ntransfer_function\nstr\ntransfer function.\n'tanh'\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\noutput\n\n\n\nstep\nPerforms one update of the internal variables.\n\n\n\n\n\nRecurrentLayer.output(self)\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\na vector of activities.\n\n\n\n\n\n\n\nRecurrentLayer.step(self)\nPerforms one update of the internal variables.\n\n\n\n\n\nLinearReadout(self, size)\nLinear readout layer. Performs a weighted sum of its inputs, without dynamics.\n\\mathbf{z} = W^o \\times \\mathbf{r}\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsize\nint\nnumber of neurons.\nrequired\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\noutput\n\n\n\nstep\nPerforms one update of the internal variables.\n\n\n\n\n\nLinearReadout.output(self)\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.ndarray\na vector of activities.\n\n\n\n\n\n\n\nLinearReadout.step(self, force=None)\nPerforms one update of the internal variables.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nforce\nnumpy.ndarray\nif not None, force the output to the provided vector.\nNone\n\n\n\n\n\n\n\n\n\nStaticInput(self, size)\nStatic placeholder for input vectors.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsize\nint\nsize of the vector.\nrequired\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\noutput\n\n\n\nset\nSets the value of the vector. The dimensions must match with self.size.\n\n\nstep\nDoes nothing.\n\n\n\n\n\nStaticInput.output(self)\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.ndarray\na vector of activities.\n\n\n\n\n\n\n\nStaticInput.set(self, value)\nSets the value of the vector. The dimensions must match with self.size.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvalue\nnumpy.ndarray\nnew vector value.\nrequired\n\n\n\n\n\n\n\nStaticInput.step(self)\nDoes nothing.\n\n\n\n\n\nTimeSeriesInput(self, size, loop=True)\nDynamic placeholder for series of input vectors.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsize\nint\nsize of the input vector.\nrequired\n\n\nloop\nbool\ndefines whether the buffer loops when arriving at the end.\nTrue\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\noutput\n\n\n\nreset\nResets the buffer.\n\n\nset\nSets the buffer to value.\n\n\nstep\nReads the next value.\n\n\n\n\n\nTimeSeriesInput.output(self)\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.ndarray\na vector of activities.\n\n\n\n\n\n\n\nTimeSeriesInput.reset(self)\nResets the buffer.\n\n\n\nTimeSeriesInput.set(self, value)\nSets the buffer to value.\n\n\n\nTimeSeriesInput.step(self)\nReads the next value."
  },
  {
    "objectID": "reference/index.qmd.html#water_tank.RecurrentLayer",
    "href": "reference/index.qmd.html#water_tank.RecurrentLayer",
    "title": "Layers",
    "section": "",
    "text": "RecurrentLayer(self, size, tau=10.0, transfer_function='tanh')\nReservoir of recurrently connected neurons.\n\\tau \\, \\frac{d \\mathbf{x}(t)}{dt} + \\mathbf{x}(t) = W^\\text{in} \\times I(t) + W^\\text{rec} \\times \\mathbf{r}(t) + W^\\text{fb} \\times \\mathbf{z}(t)\n\\mathbf{r}(t) = f(\\mathbf{x}(t))\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsize\nint\nnumber of neurons.\nrequired\n\n\ntau\nfloat\ntime constant.\n10.0\n\n\ntransfer_function\nstr\ntransfer function.\n'tanh'\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\noutput\n\n\n\nstep\nPerforms one update of the internal variables.\n\n\n\n\n\nRecurrentLayer.output(self)\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\na vector of activities.\n\n\n\n\n\n\n\nRecurrentLayer.step(self)\nPerforms one update of the internal variables."
  },
  {
    "objectID": "reference/index.qmd.html#water_tank.LinearReadout",
    "href": "reference/index.qmd.html#water_tank.LinearReadout",
    "title": "Layers",
    "section": "",
    "text": "LinearReadout(self, size)\nLinear readout layer. Performs a weighted sum of its inputs, without dynamics.\n\\mathbf{z} = W^o \\times \\mathbf{r}\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsize\nint\nnumber of neurons.\nrequired\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\noutput\n\n\n\nstep\nPerforms one update of the internal variables.\n\n\n\n\n\nLinearReadout.output(self)\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.ndarray\na vector of activities.\n\n\n\n\n\n\n\nLinearReadout.step(self, force=None)\nPerforms one update of the internal variables.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nforce\nnumpy.ndarray\nif not None, force the output to the provided vector.\nNone"
  },
  {
    "objectID": "reference/index.qmd.html#water_tank.StaticInput",
    "href": "reference/index.qmd.html#water_tank.StaticInput",
    "title": "Layers",
    "section": "",
    "text": "StaticInput(self, size)\nStatic placeholder for input vectors.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsize\nint\nsize of the vector.\nrequired\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\noutput\n\n\n\nset\nSets the value of the vector. The dimensions must match with self.size.\n\n\nstep\nDoes nothing.\n\n\n\n\n\nStaticInput.output(self)\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.ndarray\na vector of activities.\n\n\n\n\n\n\n\nStaticInput.set(self, value)\nSets the value of the vector. The dimensions must match with self.size.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvalue\nnumpy.ndarray\nnew vector value.\nrequired\n\n\n\n\n\n\n\nStaticInput.step(self)\nDoes nothing."
  },
  {
    "objectID": "reference/index.qmd.html#water_tank.TimeSeriesInput",
    "href": "reference/index.qmd.html#water_tank.TimeSeriesInput",
    "title": "Layers",
    "section": "",
    "text": "TimeSeriesInput(self, size, loop=True)\nDynamic placeholder for series of input vectors.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsize\nint\nsize of the input vector.\nrequired\n\n\nloop\nbool\ndefines whether the buffer loops when arriving at the end.\nTrue\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\noutput\n\n\n\nreset\nResets the buffer.\n\n\nset\nSets the buffer to value.\n\n\nstep\nReads the next value.\n\n\n\n\n\nTimeSeriesInput.output(self)\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.ndarray\na vector of activities.\n\n\n\n\n\n\n\nTimeSeriesInput.reset(self)\nResets the buffer.\n\n\n\nTimeSeriesInput.set(self, value)\nSets the buffer to value.\n\n\n\nTimeSeriesInput.step(self)\nReads the next value."
  },
  {
    "objectID": "reference/index.qmd.html#water_tank.connect",
    "href": "reference/index.qmd.html#water_tank.connect",
    "title": "Layers",
    "section": "connect",
    "text": "connect\nconnect(pre, post, weights, bias=None, sparseness=1.0)\nConnects two layers with a (sparse) weight matrix and optionally a bias vector.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npre\nLayer\ninput layer.\nrequired\n\n\npost\nLayer\noutput layer.\nrequired\n\n\nweights\ntyping.Union[float, water_tank.RandomDistributions.RandomDistribution]\nfloat or RandomDistribution to create the weight matrix.\nrequired\n\n\nbias\ntyping.Union[float, water_tank.RandomDistributions.RandomDistribution]\nbias per post neuron. If None or False, no bias is used. Otherwise, can be a float or RandomDistribution.\nNone\n\n\nsparseness\nfloat\ndensity of the weight matrix.\n1.0\n\n\n\n\n\nReturns\n\n\n\nType\nDescription\n\n\n\n\nProjection\na DenseProjection or SparseProjection instance."
  },
  {
    "objectID": "reference/index.qmd.html#water_tank.DenseProjection",
    "href": "reference/index.qmd.html#water_tank.DenseProjection",
    "title": "Layers",
    "section": "DenseProjection",
    "text": "DenseProjection\nDenseProjection(self, pre, post, weights, bias=None)\nDense weight matrix. Created and returned by connect().\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npre\nLayer\ninput layer.\nrequired\n\n\npost\nLayer\noutput layer.\nrequired\n\n\nweights\ntyping.Union[float, water_tank.RandomDistributions.RandomDistribution]\nfloat or RandomDistribution to create the weight matrix.\nrequired\n\n\nbias\ntyping.Union[float, water_tank.RandomDistributions.RandomDistribution]\nbias per post neuron. If None or False, no bias is used. Otherwise, can be a float or RandomDistribution.\nNone\n\n\n\n\n\nMethods\n\n\n\nName\nDescription\n\n\n\n\ninput\n\n\n\nnb_connections\n\n\n\nstep\nPerforms a weighted sum of inputs plus bias.\n\n\n\n\ninput\nDenseProjection.input(self, idx)\n\nReturns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.ndarray\nthe vector of inputs received by the neuron of index idx.\n\n\n\n\n\n\nnb_connections\nDenseProjection.nb_connections(self, idx)\n\nReturns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nint\nthe number of weights received by the neuron of index idx.\n\n\n\n\n\n\nstep\nDenseProjection.step(self)\nPerforms a weighted sum of inputs plus bias."
  },
  {
    "objectID": "reference/index.qmd.html#water_tank.SparseProjection",
    "href": "reference/index.qmd.html#water_tank.SparseProjection",
    "title": "Layers",
    "section": "SparseProjection",
    "text": "SparseProjection\nSparseProjection(self, pre, post, weights, bias=None, sparseness=0.1)\nSparse weight matrix. Created and returned by connect().\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npre\nLayer\ninput layer.\nrequired\n\n\npost\nLayer\noutput layer.\nrequired\n\n\nweights\ntyping.Union[float, water_tank.RandomDistributions.RandomDistribution]\nfloat or RandomDistribution to create the weight matrix.\nrequired\n\n\nbias\ntyping.Union[float, water_tank.RandomDistributions.RandomDistribution]\nbias per post neuron. If None or False, no bias is used. Otherwise, can be a float or RandomDistribution.\nNone\n\n\nsparseness\nfloat\ndensity of the weight matrix.\n0.1\n\n\n\n\n\nMethods\n\n\n\nName\nDescription\n\n\n\n\ninput\n\n\n\nnb_connections\n\n\n\nstep\nPerforms a weighted sum of inputs plus bias.\n\n\n\n\ninput\nSparseProjection.input(self, idx)\n\nReturns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.ndarray\nthe vector of inputs received by the neuron of index idx.\n\n\n\n\n\n\nnb_connections\nSparseProjection.nb_connections(self, idx)\n\nReturns\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nint\nthe number of weights received by the neuron of index idx.\n\n\n\n\n\n\nstep\nSparseProjection.step(self)\nPerforms a weighted sum of inputs plus bias."
  },
  {
    "objectID": "reference/index.qmd.html#water_tank.DeltaLearningRule",
    "href": "reference/index.qmd.html#water_tank.DeltaLearningRule",
    "title": "Layers",
    "section": "DeltaLearningRule",
    "text": "DeltaLearningRule\nDeltaLearningRule(self, projection, learning_rate)"
  },
  {
    "objectID": "reference/index.qmd.html#water_tank.RLS",
    "href": "reference/index.qmd.html#water_tank.RLS",
    "title": "Layers",
    "section": "RLS",
    "text": "RLS\nRLS(self, projection, delta)\nRecursive least-squares (RLS) learning rule for FORCE learning."
  },
  {
    "objectID": "reference/index.qmd.html#water_tank.Const",
    "href": "reference/index.qmd.html#water_tank.Const",
    "title": "Layers",
    "section": "Const",
    "text": "Const\nConst(self, value)\nConstant “random” distribution, returning the same value.\n\nParameters\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvalue\nfloat\nconstant value.\nrequired\n\n\n\n\n\nMethods\n\n\n\nName\nDescription\n\n\n\n\nsample\nSamples from the distribution and returns an array of the desired shape.\n\n\n\n\nsample\nConst.sample(self, shape)\nSamples from the distribution and returns an array of the desired shape."
  },
  {
    "objectID": "reference/index.qmd.html#water_tank.Uniform",
    "href": "reference/index.qmd.html#water_tank.Uniform",
    "title": "Layers",
    "section": "Uniform",
    "text": "Uniform\nUniform(self, min, max)\nUniform distribution, returning values between min and max.\n\nParameters\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmin\nfloat\nlower bound.\nrequired\n\n\nmax\nfloat\nupper bound.\nrequired\n\n\n\n\n\nMethods\n\n\n\nName\nDescription\n\n\n\n\nsample\nSamples from the distribution and returns an array of the desired shape.\n\n\n\n\nsample\nUniform.sample(self, shape)\nSamples from the distribution and returns an array of the desired shape."
  },
  {
    "objectID": "reference/index.qmd.html#water_tank.Normal",
    "href": "reference/index.qmd.html#water_tank.Normal",
    "title": "Layers",
    "section": "Normal",
    "text": "Normal\nNormal(self, mean, std)\nNormal distribution, returning values with a mean of mean and a standard deviation of std.\n\nParameters\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmean\nfloat\nmean.\nrequired\n\n\nstd\nfloat\nstandard deviation.\nrequired\n\n\n\n\n\nMethods\n\n\n\nName\nDescription\n\n\n\n\nsample\nSamples from the distribution and returns an array of the desired shape.\n\n\n\n\nsample\nNormal.sample(self, shape)\nSamples from the distribution and returns an array of the desired shape."
  },
  {
    "objectID": "reference/index.qmd.html#water_tank.Bernouilli",
    "href": "reference/index.qmd.html#water_tank.Bernouilli",
    "title": "Layers",
    "section": "Bernouilli",
    "text": "Bernouilli\nBernouilli(self, values, p=0.5)\nBernouilli (binomial) distribution, returning the first of the two values with probability p.\n\nParameters\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvalues\nlist\nlist of values.\nrequired\n\n\np\nfloat\nprobability of returning the first value.\n0.5\n\n\n\n\n\nMethods\n\n\n\nName\nDescription\n\n\n\n\nsample\nSamples from the distribution and returns an array of the desired shape.\n\n\n\n\nsample\nBernouilli.sample(self, shape)\nSamples from the distribution and returns an array of the desired shape."
  },
  {
    "objectID": "reference/Reservoir.html",
    "href": "reference/Reservoir.html",
    "title": "Reservoir",
    "section": "",
    "text": "Reservoir(self, size, tau=10.0, transfer_function='tanh')\nReservoir of recurrent neurons.\n\\tau \\, \\frac{d \\mathbf{x}(t)}{dt} + \\mathbf{x}(t) = W^\\text{in} \\times I(t) + W^\\text{rec} \\times \\mathbf{r}(t) + W^\\text{fb} \\times \\mathbf{z}(t)\n\\mathbf{r}(t) = f(\\mathbf{x}(t))\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsize\nint\nnumber of neurons.\nrequired\n\n\ntau\nfloat\ntime constant.\n10.0\n\n\ntransfer_function\nstr\ntransfer function.\n'tanh'\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\noutput\n\n\n\nstep\nPerforms one update of the internal variables.\n\n\n\n\n\nReservoir.output(self)\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\na vector of activities.\n\n\n\n\n\n\n\nReservoir.step(self)\nPerforms one update of the internal variables."
  },
  {
    "objectID": "reference/Reservoir.html#parameters",
    "href": "reference/Reservoir.html#parameters",
    "title": "Reservoir",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nsize\nint\nnumber of neurons.\nrequired\n\n\ntau\nfloat\ntime constant.\n10.0\n\n\ntransfer_function\nstr\ntransfer function.\n'tanh'"
  },
  {
    "objectID": "reference/Reservoir.html#methods",
    "href": "reference/Reservoir.html#methods",
    "title": "Reservoir",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\noutput\n\n\n\nstep\nPerforms one update of the internal variables.\n\n\n\n\n\nReservoir.output(self)\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\na vector of activities.\n\n\n\n\n\n\n\nReservoir.step(self)\nPerforms one update of the internal variables."
  }
]